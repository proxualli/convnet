<?xml version='1.0' encoding='utf-8'?>
<SettingsFile xmlns="http://schemas.microsoft.com/VisualStudio/2004/01/settings" CurrentProfile="(Default)" GeneratedClassNamespace="Convnet.Properties" GeneratedClassName="Settings">
  <Profiles />
  <Settings>
    <Setting Name="PixelSize" Type="System.Double" Scope="User">
      <Value Profile="(Default)">3</Value>
    </Setting>
    <Setting Name="RefreshInterval" Type="System.Int32" Scope="User">
      <Value Profile="(Default)">60</Value>
    </Setting>
    <Setting Name="Optimizer" Type="System.Int32" Scope="User">
      <Value Profile="(Default)">4</Value>
    </Setting>
    <Setting Name="CurrentPage" Type="System.Int32" Scope="User">
      <Value Profile="(Default)">0</Value>
    </Setting>
    <Setting Name="AdaGradEps" Type="System.Single" Scope="User">
      <Value Profile="(Default)">1E-08</Value>
    </Setting>
    <Setting Name="AdamEps" Type="System.Single" Scope="User">
      <Value Profile="(Default)">1E-08</Value>
    </Setting>
    <Setting Name="AdamBeta2" Type="System.Single" Scope="User">
      <Value Profile="(Default)">0.999</Value>
    </Setting>
    <Setting Name="RMSpropEps" Type="System.Single" Scope="User">
      <Value Profile="(Default)">1E-08</Value>
    </Setting>
    <Setting Name="DefaultLearningRateAdaGrad" Type="System.Single" Scope="User">
      <Value Profile="(Default)">0.01</Value>
    </Setting>
    <Setting Name="DefaultLearningRateAdam" Type="System.Single" Scope="User">
      <Value Profile="(Default)">0.001</Value>
    </Setting>
    <Setting Name="DefaultLearningRateRMSProp" Type="System.Single" Scope="User">
      <Value Profile="(Default)">0.0001</Value>
    </Setting>
    <Setting Name="DefaultLearningRateSGD" Type="System.Single" Scope="User">
      <Value Profile="(Default)">0.01</Value>
    </Setting>
    <Setting Name="DefaultLearningRateSGDMomentum" Type="System.Single" Scope="User">
      <Value Profile="(Default)">0.01</Value>
    </Setting>
    <Setting Name="DefaultMomentumAdam" Type="System.Single" Scope="User">
      <Value Profile="(Default)">0.9</Value>
    </Setting>
    <Setting Name="DefaultMomentumRMSProp" Type="System.Single" Scope="User">
      <Value Profile="(Default)">0.99</Value>
    </Setting>
    <Setting Name="Timings" Type="System.Boolean" Scope="User">
      <Value Profile="(Default)">True</Value>
    </Setting>
    <Setting Name="AdamaxEps" Type="System.Single" Scope="User">
      <Value Profile="(Default)">1E-08</Value>
    </Setting>
    <Setting Name="AdamaxBeta2" Type="System.Single" Scope="User">
      <Value Profile="(Default)">0.999</Value>
    </Setting>
    <Setting Name="PersistOptimizer" Type="System.Boolean" Scope="User">
      <Value Profile="(Default)">False</Value>
    </Setting>
    <Setting Name="GoToEpoch" Type="System.UInt32" Scope="User">
      <Value Profile="(Default)">1</Value>
    </Setting>
    <Setting Name="Priority" Type="System.Diagnostics.ProcessPriorityClass" Scope="User">
      <Value Profile="(Default)">Normal</Value>
    </Setting>
    <Setting Name="PrioritySetter" Type="System.Double" Scope="User">
      <Value Profile="(Default)">3</Value>
    </Setting>
    <Setting Name="ShowTrainingPlot" Type="System.Boolean" Scope="User">
      <Value Profile="(Default)">False</Value>
    </Setting>
    <Setting Name="PlotType" Type="System.UInt32" Scope="User">
      <Value Profile="(Default)">1</Value>
    </Setting>
    <Setting Name="AdaDeltaEps" Type="System.Single" Scope="User">
      <Value Profile="(Default)">1E-08</Value>
    </Setting>
    <Setting Name="RAdamEps" Type="System.Single" Scope="User">
      <Value Profile="(Default)">1E-08</Value>
    </Setting>
    <Setting Name="RAdamBeta1" Type="System.Single" Scope="User">
      <Value Profile="(Default)">0.9</Value>
    </Setting>
    <Setting Name="RAdamBeta2" Type="System.Single" Scope="User">
      <Value Profile="(Default)">0.999</Value>
    </Setting>
    <Setting Name="DefaultMomentumSGDMomentum" Type="System.Single" Scope="User">
      <Value Profile="(Default)">0.9</Value>
    </Setting>
    <Setting Name="DefinitionEditing" Type="System.String" Scope="User">
      <Value Profile="(Default)">[resnet-32-4-3-2-6-dropout-channelzeropad]
Dataset=CIFAR10
Dim=3,32,32
ZeroPad=4,4
RandomCrop=Yes
WeightsFiller=HeNormal
Biases=No
Momentum=0.995
Scaling=No

[C1]
Type=Convolution
Inputs=Input
Channels=96
Kernel=3,3
Pad=1,1

[B1]
Type=BatchNormRelu
Inputs=C1

[C2]
Type=Convolution
Inputs=B1
Channels=96
Kernel=3,3
Pad=1,1

[B2]
Type=BatchNormReluDropout
Inputs=C2
Dropout=0.3

[C3]
Type=Convolution
Inputs=B2
Channels=96
Kernel=3,3
Pad=1,1

[C4]
Type=Convolution
Inputs=B1
Channels=96
Kernel=1,1

[A1]
Type=Add
Inputs=C3,C4

[B5]
Type=BatchNormRelu
Inputs=A1

[C5]
Type=Convolution
Inputs=B5
Channels=96
Kernel=3,3
Pad=1,1

[B6]
Type=BatchNormReluDropout
Inputs=C5
Dropout=0.3

[C6]
Type=Convolution
Inputs=B6
Channels=96
Kernel=3,3
Pad=1,1

[A2]
Type=Add
Inputs=C6,A1

[B7]
Type=BatchNormRelu
Inputs=A2

[C7]
Type=Convolution
Inputs=B7
Channels=192
Kernel=3,3
Stride=2,2
Pad=1,1

[B8]
Type=BatchNormReluDropout
Inputs=C7
Dropout=0.3

[C8]
Type=Convolution
Inputs=B8
Channels=192
Kernel=3,3
Pad=1,1

[AVG1]
Type=AvgPooling
Inputs=A2
Kernel=3,3
Stride=2,2
Pad=1,1

[CZP1]
Type=ChannelZeroPad
Inputs=AVG1
Channels=192

[A3]
Type=Add
Inputs=C8,CZP1

[B9]
Type=BatchNormRelu
Inputs=A3

[C9]
Type=Convolution
Inputs=B9
Channels=192
Kernel=3,3
Pad=1,1

[B10]
Type=BatchNormReluDropout
Inputs=C9
Dropout=0.3

[C10]
Type=Convolution
Inputs=B10
Channels=192
Kernel=3,3
Pad=1,1

[A4]
Type=Add
Inputs=C10,A3

[B11]
Type=BatchNormRelu
Inputs=A4

[C11]
Type=Convolution
Inputs=B11
Channels=384
Kernel=3,3
Stride=2,2
Pad=1,1

[B12]
Type=BatchNormReluDropout
Inputs=C11
Dropout=0.3

[C12]
Type=Convolution
Inputs=B12
Channels=384
Kernel=3,3
Pad=1,1

[AVG2]
Type=AvgPooling
Inputs=A4
Kernel=3,3
Stride=2,2
Pad=1,1

[CZP2]
Type=ChannelZeroPad
Inputs=AVG2
Channels=384

[A5]
Type=Add
Inputs=C12,CZP2

[B13]
Type=BatchNormRelu
Inputs=A5

[C13]
Type=Convolution
Inputs=B13
Channels=384
Kernel=3,3
Pad=1,1

[B14]
Type=BatchNormReluDropout
Inputs=C13
Dropout=0.3

[C14]
Type=Convolution
Inputs=B14
Channels=384
Kernel=3,3
Pad=1,1

[A6]
Type=Add
Inputs=C14,A5

[B15]
Type=BatchNormRelu
Inputs=A6

[C15]
Type=Convolution
Inputs=B15
Channels=10
Kernel=1,1

[B16]
Type=BatchNorm
Inputs=C15

[GAP]
Type=GlobalAvgPooling
Inputs=B16

[ACT]
Type=Activation
Inputs=GAP
Activation=Softmax

[Cost]
Type=Cost
Inputs=ACT
Cost=CategoricalCrossEntropy
Channels=10</Value>
    </Setting>
    <Setting Name="DefinitionActive" Type="System.String" Scope="User">
      <Value Profile="(Default)">[resnet-32-4-3-2-6-dropout-channelzeropad]
Dataset=CIFAR10
Dim=3,32,32
ZeroPad=4,4
RandomCrop=Yes
WeightsFiller=HeNormal
Biases=No
Momentum=0.995
Scaling=No

[C1]
Type=Convolution
Inputs=Input
Channels=96
Kernel=3,3
Pad=1,1

[B1]
Type=BatchNormRelu
Inputs=C1

[C2]
Type=Convolution
Inputs=B1
Channels=96
Kernel=3,3
Pad=1,1

[B2]
Type=BatchNormReluDropout
Inputs=C2
Dropout=0.3

[C3]
Type=Convolution
Inputs=B2
Channels=96
Kernel=3,3
Pad=1,1

[C4]
Type=Convolution
Inputs=B1
Channels=96
Kernel=1,1

[A1]
Type=Add
Inputs=C3,C4

[B5]
Type=BatchNormRelu
Inputs=A1

[C5]
Type=Convolution
Inputs=B5
Channels=96
Kernel=3,3
Pad=1,1

[B6]
Type=BatchNormReluDropout
Inputs=C5
Dropout=0.3

[C6]
Type=Convolution
Inputs=B6
Channels=96
Kernel=3,3
Pad=1,1

[A2]
Type=Add
Inputs=C6,A1

[B7]
Type=BatchNormRelu
Inputs=A2

[C7]
Type=Convolution
Inputs=B7
Channels=192
Kernel=3,3
Stride=2,2
Pad=1,1

[B8]
Type=BatchNormReluDropout
Inputs=C7
Dropout=0.3

[C8]
Type=Convolution
Inputs=B8
Channels=192
Kernel=3,3
Pad=1,1

[AVG1]
Type=AvgPooling
Inputs=A2
Kernel=3,3
Stride=2,2
Pad=1,1

[CZP1]
Type=ChannelZeroPad
Inputs=AVG1
Channels=192

[A3]
Type=Add
Inputs=C8,CZP1

[B9]
Type=BatchNormRelu
Inputs=A3

[C9]
Type=Convolution
Inputs=B9
Channels=192
Kernel=3,3
Pad=1,1

[B10]
Type=BatchNormReluDropout
Inputs=C9
Dropout=0.3

[C10]
Type=Convolution
Inputs=B10
Channels=192
Kernel=3,3
Pad=1,1

[A4]
Type=Add
Inputs=C10,A3

[B11]
Type=BatchNormRelu
Inputs=A4

[C11]
Type=Convolution
Inputs=B11
Channels=384
Kernel=3,3
Stride=2,2
Pad=1,1

[B12]
Type=BatchNormReluDropout
Inputs=C11
Dropout=0.3

[C12]
Type=Convolution
Inputs=B12
Channels=384
Kernel=3,3
Pad=1,1

[AVG2]
Type=AvgPooling
Inputs=A4
Kernel=3,3
Stride=2,2
Pad=1,1

[CZP2]
Type=ChannelZeroPad
Inputs=AVG2
Channels=384

[A5]
Type=Add
Inputs=C12,CZP2

[B13]
Type=BatchNormRelu
Inputs=A5

[C13]
Type=Convolution
Inputs=B13
Channels=384
Kernel=3,3
Pad=1,1

[B14]
Type=BatchNormReluDropout
Inputs=C13
Dropout=0.3

[C14]
Type=Convolution
Inputs=B14
Channels=384
Kernel=3,3
Pad=1,1

[A6]
Type=Add
Inputs=C14,A5

[B15]
Type=BatchNormRelu
Inputs=A6

[C15]
Type=Convolution
Inputs=B15
Channels=10
Kernel=1,1

[B16]
Type=BatchNorm
Inputs=C15

[GAP]
Type=GlobalAvgPooling
Inputs=B16

[ACT]
Type=Activation
Inputs=GAP
Activation=Softmax

[Cost]
Type=Cost
Inputs=ACT
Cost=CategoricalCrossEntropy
Channels=10</Value>
    </Setting>
    <Setting Name="ModelNameActive" Type="System.String" Scope="User">
      <Value Profile="(Default)">resnet-32-4-3-2-6-dropout-channelzeropad</Value>
    </Setting>
    <Setting Name="EditSplitPositionA" Type="System.Windows.GridLength" Scope="User">
      <Value Profile="(Default)">420</Value>
    </Setting>
    <Setting Name="SelectedLayer" Type="System.Int32" Scope="User">
      <Value Profile="(Default)">0</Value>
    </Setting>
    <Setting Name="DisableLocking" Type="System.Boolean" Scope="User">
      <Value Profile="(Default)">True</Value>
    </Setting>
    <Setting Name="Script" Type="System.String" Scope="User">
      <Value Profile="(Default)">using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Diagnostics;
using System.Globalization;
using System.Linq;

using Float = System.Single;
using size_t = System.UInt64;

namespace Convnet
{
public class ScriptsCatalogDynamic
{
    public const string nwl = "\r\n";

    public static string to_string(bool variable)
    {
        return variable ? "Yes" : "No";
    }

    public static string to_string(size_t number)
    {
        return number.ToString();
    }

    public static string to_string(Float number)
    {
        var ci = new CultureInfo("en-US");
        return number.ToString(ci);
    }

    public static string to_string(Datasets dataset)
    {
        return dataset.ToString();
    }

    public static string to_string(Fillers filler)
    {
        return filler.ToString();
    }

    public static size_t DIV8(size_t channels)
    {
        if (channels % 8ul == 0ul)
            return channels;

        return ((channels / 8ul) + 1ul) * 8ul;
    }

    public static string In(string prefix, size_t id)
    {
        return prefix + to_string(id);
    }

    public static string BatchNorm(size_t id, string inputs, string group = "", string prefix = "B")
    {
        return "[" + group + prefix + to_string(id) + "]" + nwl +
           "Type=BatchNorm" + nwl +
           "Inputs=" + inputs + nwl + nwl;
    }

    public static string BatchNormRelu(size_t id, string inputs, string group = "", string prefix = "B")
    {
        return "[" + group + prefix + to_string(id) + "]" + nwl +
           "Type=BatchNormRelu" + nwl +
           "Inputs=" + inputs + nwl + nwl;
    }

    public static string BatchNormReluDropout(size_t id, string inputs, string group = "", string prefix = "B")
    {
        return "[" + group + prefix + to_string(id) + "]" + nwl +
           "Type=BatchNormReluDropout" + nwl +
           "Inputs=" + inputs + nwl + nwl;
    }

    public static string Convolution(size_t id, string inputs, size_t channels, size_t kernelX = 3, size_t kernelY = 3, size_t strideX = 1, size_t strideY = 1, size_t padX = 1, size_t padY = 1, string group = "", string prefix = "C")
    {
        return "[" + group + prefix + to_string(id) + "]" + nwl +
            "Type=Convolution" + nwl +
            "Inputs=" + inputs + nwl +
            "Channels=" + to_string(channels) + nwl +
            "Kernel=" + to_string(kernelX) + "," + to_string(kernelY) + nwl +
            (strideX != 1 || strideY != 1 ? "Stride=" + to_string(strideX) + "," + to_string(strideY) + nwl : "") +
            (padX != 0 || padY != 0 ? "Pad=" + to_string(padX) + "," + to_string(padY) + nwl + nwl : nwl);
    }

    public static string DepthwiseConvolution(size_t id, string inputs, size_t multiplier = 1, size_t kernelX = 3, size_t kernelY = 3, size_t strideX = 1, size_t strideY = 1, size_t padX = 1, size_t padY = 1, string group = "", string prefix = "DC")
    {
        return "[" + group + prefix + to_string(id) + "]" + nwl +
            "Type=DepthwiseConvolution" + nwl +
            "Inputs=" + inputs + nwl +
            (multiplier &gt; 1 ? "Multiplier=" + to_string(multiplier) + nwl : "") +
            "Kernel=" + to_string(kernelX) + "," + to_string(kernelY) + nwl +
            (strideX != 1 || strideY != 1 ? "Stride=" + to_string(strideX) + "," + to_string(strideY) + nwl : "") +
            (padX != 0 || padY != 0 ? "Pad=" + to_string(padX) + "," + to_string(padY) + nwl + nwl : nwl);
    }

    public static string PartialDepthwiseConvolution(size_t id, string inputs, size_t part = 1, size_t groups = 1, size_t kernelX = 3, size_t kernelY = 3, size_t strideX = 1, size_t strideY = 1, size_t padX = 1, size_t padY = 1, string group = "", string prefix = "DC")
    {
        return "[" + group + prefix + to_string(id) + "]" + nwl +
            "Type=PartialDepthwiseConvolution" + nwl +
            "Inputs=" + inputs + nwl +
            "Group=" + to_string(part) + nwl +
            "Groups=" + to_string(groups) + nwl +
            "Kernel=" + to_string(kernelX) + "," + to_string(kernelY) + nwl +
            (strideX != 1 || strideY != 1 ? "Stride=" + to_string(strideX) + "," + to_string(strideY) + nwl : "") +
            (padX != 0 || padY != 0 ? "Pad=" + to_string(padX) + "," + to_string(padY) + nwl + nwl : nwl);
    }

    public static string DepthwiseMixedConvolution(size_t g, size_t id, string inputs, size_t strideX = 1, size_t strideY = 1, bool useChannelSplit = true, string group = "", string prefix = "DC")
    {
        switch (g)
        {
            case 0:
                return DepthwiseConvolution(id, inputs, 1, 3, 3, strideX, strideY, 1, 1, group, prefix);

            case 1:
                return useChannelSplit ? ChannelSplit(id, inputs, 2, 1, "Q1") + ChannelSplit(id, inputs, 2, 2, "Q2") +
                    DepthwiseConvolution(id, In("Q1CS", id), 1, 3, 3, strideX, strideY, 1, 1, "A") + DepthwiseConvolution(id, In("Q2CS", id), 1, 5, 5, strideX, strideY, 2, 2, "B") +
                    Concat(id, In("ADC", id) + "," + In("BDC", id), group, prefix) :
                    PartialDepthwiseConvolution(id, inputs, 1, 2, 3, 3, strideX, strideY, 1, 1, "A") + PartialDepthwiseConvolution(id, inputs, 2, 2, 5, 5, strideX, strideY, 2, 2, "B") +
                    Concat(id, In("ADC", id) + "," + In("BDC", id), group, prefix);

            case 2:
                return useChannelSplit ? ChannelSplit(id, inputs, 3, 1, "Q1") + ChannelSplit(id, inputs, 3, 2, "Q2") + ChannelSplit(id, inputs, 3, 3, "Q3") +
                    DepthwiseConvolution(id, In("Q1CS", id), 1, 3, 3, strideX, strideY, 1, 1, "A") + DepthwiseConvolution(id, In("Q2CS", id), 1, 5, 5, strideX, strideY, 2, 2, "B") + DepthwiseConvolution(id, In("Q3CS", id), 1, 7, 7, strideX, strideY, 3, 3, "C") +
                    Concat(id, In("ADC", id) + "," + In("BDC", id) + "," + In("CDC", id), group, prefix) :
                    PartialDepthwiseConvolution(id, inputs, 1, 3, 3, 3, strideX, strideY, 1, 1, "A") + PartialDepthwiseConvolution(id, inputs, 2, 3, 5, 5, strideX, strideY, 2, 2, "B") +
                    PartialDepthwiseConvolution(id, inputs, 3, 3, 7, 7, strideX, strideY, 3, 3, "C") +
                    Concat(id, In("ADC", id) + "," + In("BDC", id) + "," + In("CDC", id), group, prefix);
            default:
                return useChannelSplit ? ChannelSplit(id, inputs, 4, 1, "Q1") + ChannelSplit(id, inputs, 4, 2, "Q2") + ChannelSplit(id, inputs, 4, 3, "Q3") + ChannelSplit(id, inputs, 4, 4, "Q4") +
                    DepthwiseConvolution(id, In("Q1CS", id), 1, 3, 3, strideX, strideY, 1, 1, "A") + DepthwiseConvolution(id, In("Q2CS", id), 1, 5, 5, strideX, strideY, 2, 2, "B") +
                    DepthwiseConvolution(id, In("Q3CS", id), 1, 7, 7, strideX, strideY, 3, 3, "C") + DepthwiseConvolution(id, In("Q4CS", id), 1, 9, 9, strideX, strideY, 4, 4, "D") +
                    Concat(id, In("ADC", id) + "," + In("BDC", id) + "," + In("CDC", id) + "," + In("DDC", id), group, prefix) :
                    PartialDepthwiseConvolution(id, inputs, 1, 4, 3, 3, strideX, strideY, 1, 1, "A") + PartialDepthwiseConvolution(id, inputs, 2, 4, 5, 5, strideX, strideY, 2, 2, "B") +
                    PartialDepthwiseConvolution(id, inputs, 3, 4, 7, 7, strideX, strideY, 3, 3, "C") + PartialDepthwiseConvolution(id, inputs, 4, 4, 9, 9, strideX, strideY, 4, 4, "D") +
                    Concat(id, In("ADC", id) + "," + In("BDC", id) + "," + In("CDC", id) + "," + In("DDC", id), group, prefix);
        }
    }

    public static string ChannelSplit(size_t id, string inputs, size_t groups, size_t part, string group = "", string prefix = "CS")
    {
        return "[" + group + prefix + to_string(id) + "]" + nwl +
           "Type=ChannelSplit" + nwl +
           "Inputs=" + inputs + nwl +
           "Groups=" + to_string(groups) + nwl +
           "Group=" + to_string(part) + nwl + nwl;
    }

    public static string ChannelShuffle(size_t id, string inputs, size_t groups = 2, string group = "", string prefix = "CSH")
    {
        return "[" + group + prefix + to_string(id) + "]" + nwl +
           "Type=ChannelShuffle" + nwl +
           "Inputs=" + inputs + nwl +
           "Groups=" + to_string(groups) + nwl + nwl;
    }

    public static string Concat(size_t id, string inputs, string group = "", string prefix = "CC")
    {
        return "[" + group + prefix + to_string(id) + "]" + nwl +
           "Type=Concat" + nwl +
           "Inputs=" + inputs + nwl + nwl;
    }

    public static string GlobalAvgPooling(string input, string group = "", string prefix = "GAP")
    {
        return "[" + group + prefix + "]" + nwl +
            "Type=GlobalAvgPooling" + nwl +
            "Inputs=" + input + nwl + nwl;
    }

    public static string BatchNormHardLogistic(size_t id, string inputs, string group = "", string prefix = "B")
    {
        return "[" + group + prefix + to_string(id) + "]" + nwl +
          "Type=BatchNormHardLogistic" + nwl +
          "Inputs=" + inputs + nwl + nwl;
    }

    public static string BatchNormHardSwish(size_t id, string inputs, string group = "", string prefix = "B")
    {
        return "[" + group + prefix + to_string(id) + "]" + nwl +
          "Type=BatchNormHardSwish" + nwl +
          "Inputs=" + inputs + nwl + nwl;
    }

    public static string Add(size_t id, string inputs, string group = "", string prefix = "A")
    {
        return "[" + group + prefix + to_string(id) + "]" + nwl +
           "Type=Add" + nwl +
           "Inputs=" + inputs + nwl + nwl;
    }

    public static string ChannelMultiply(string inputs, string group = "", string prefix = "CM")
    {
        return "[" + group + prefix + "]" + nwl +
           "Type=ChannelMultiply" + nwl +
           "Inputs=" + inputs + nwl + nwl;
    }

    public static string Dropout(size_t id, string inputs, string group = "", string prefix = "D")
    {
        return "[" + group + prefix + to_string(id) + "]" + nwl +
           "Type=Dropout" + nwl +
           "Inputs=" + inputs + nwl + nwl;
    }

    public static string Generate(Convnet.ScriptParameters p)
    {

        var net =
            "[" + p.ModelName + "]" + nwl +
            "Dataset=" + to_string(p.Dataset) + nwl +
            "Dim=" + to_string(p.C) + "," + to_string(p.H) + "," + to_string(p.W) + nwl +
            ((p.PadH &gt; 0 || p.PadW &gt; 0) ? (!p.MirrorPad ? "ZeroPad=" + to_string(p.PadH) + "," + to_string(p.PadW) + nwl : "MirrorPad=" + to_string(p.PadH) + "," + to_string(p.PadW) + nwl) : "") +
            ((p.PadH &gt; 0 || p.PadW &gt; 0) ? "RandomCrop=Yes" + nwl : "") +
            "WeightsFiller=" + to_string(p.WeightsFiller) + (p.WeightsScaleVisible ? "(" + to_string(p.WeightsScale) + ")" : "") + nwl +
            (p.WeightsLRM != 1 ? "WeightsLRM=" + to_string(p.WeightsLRM) + nwl : "") +
            (p.WeightsWDM != 1 ? "WeightsWDM=" + to_string(p.WeightsWDM) + nwl : "") +
            (p.HasBias ? "BiasesFiller=" + to_string(p.BiasesFiller) + (p.BiasesScaleVisible ? "(" + to_string(p.BiasesScale) + ")" : "") + nwl +
            (p.BiasesLRM != 1 ? "BiasesLRM=" + to_string(p.BiasesLRM) + nwl : "") +
            (p.BiasesWDM != 1 ? "BiasesWDM=" + to_string(p.BiasesWDM) + nwl : "") : "Biases=No" + nwl) +
            (p.DropoutVisible ? "Dropout=" + to_string(p.Dropout) + nwl : "") +
            "Scaling=" + to_string(p.BatchNormScaling) + nwl +
            "Momentum=" + to_string(p.BatchNormMomentum) + nwl +
            "Eps=" + to_string(p.BatchNormEps) + nwl + nwl;

        var blocks = new List&lt;string&gt;();

        switch (p.Script)
        {
            case Scripts.densenet:
                {
                    var channels = DIV8(p.GrowthRate);

                    net += Convolution(1, "Input", channels, 3, 3, 1, 1, 1, 1);

                    if (p.Bottleneck)
                    {
                        blocks.Add(
                            BatchNormRelu(1, "C1") +
                            Convolution(2, "B1", DIV8(4 * p.GrowthRate), 1, 1, 1, 1, 0, 0) +
                            BatchNormRelu(2, "C2") +
                            Convolution(3, "B2", DIV8(p.GrowthRate), 3, 3, 1, 1, 1, 1) +
                            (p.Dropout &gt; 0 ? Dropout(3, "C3") + Concat(1, "C1,D3") : Concat(1, "C1,C3")));
                    }
                    else
                    {
                        blocks.Add(
                            BatchNormRelu(1, "C1") +
                            Convolution(2, "B1", DIV8(p.GrowthRate), 3, 3, 1, 1, 1, 1) +
                            (p.Dropout &gt; 0 ? Dropout(2, "C2") + Concat(1, "C1,D2") : Concat(1, "C1,C2")));
                    }

                    var CC = 1ul;
                    var C = p.Bottleneck ? 4ul : 3ul;

                    channels += p.GrowthRate;

                    for (var g = 1ul; g &lt;= p.Groups; g++)  // 32*32 16*16 8*8 or 28*28 14*14 7*7
                    {
                        for (var i = 1ul; i &lt; p.Iterations; i++)
                        {
                            if (p.Bottleneck)
                            {
                                blocks.Add(
                                    BatchNormRelu(C, In("CC", CC)) +
                                    Convolution(C, In("B", C), DIV8(4 * p.GrowthRate), 1, 1, 1, 1, 0, 0) +
                                    BatchNormRelu(C + 1, In("C", C)) +
                                    Convolution(C + 1, In("B", C + 1), DIV8(p.GrowthRate), 3, 3, 1, 1, 1, 1) +
                                    (p.Dropout &gt; 0 ? Dropout(C + 1, In("C", C + 1)) + Concat(CC + 1, In("CC", CC) + "," + In("D", C + 1)) : Concat(CC + 1, In("CC", CC) + "," + In("C", C + 1))));

                                C += 2;
                            }
                            else
                            {
                                blocks.Add(
                                    BatchNormRelu(C, In("CC", CC)) +
                                    Convolution(C, In("B", C), DIV8(p.GrowthRate), 3, 3, 1, 1, 1, 1) +
                                    (p.Dropout &gt; 0 ? Dropout(C, In("C", C)) + Concat(CC + 1, In("CC", CC) + "," + In("D", C)) : Concat(CC + 1, In("CC", CC) + "," + In("C", C))));

                                C++;
                            }

                            CC++;
                            channels += p.GrowthRate;
                        }

                        if (g &lt; p.Groups)
                        {
                            channels = DIV8((size_t)System.Math.Floor(2.0 * channels * p.Compression));

                            if (p.Dropout &gt; 0)
                                blocks.Add(
                                    Convolution(C, In("CC", CC), channels, 1, 1, 1, 1, 0, 0) +
                                    Dropout(C, In("C", C)) +
                                    "[P" + to_string(g) + "]" + nwl + "Type=AvgPooling" + nwl + "Inputs=D" + to_string(C) + nwl + "Kernel=2,2" + nwl + "Stride=2,2" + nwl + nwl);
                            else
                                blocks.Add(
                                    Convolution(C, "CC" + to_string(CC), channels, 1, 1, 1, 1, 0, 0) +
                                    "[P" + to_string(g) + "]" + nwl + "Type=AvgPooling" + nwl + "Inputs=C" + to_string(C) + nwl + "Kernel=2,2" + nwl + "Stride=2,2" + nwl + nwl);
                            C++;
                            CC++;

                            if (p.Bottleneck)
                            {
                                blocks.Add(
                                    BatchNormRelu(C, In("P", g)) +
                                    Convolution(C, In("B", C), DIV8(4 * p.GrowthRate), 1, 1, 1, 1, 0, 0) +
                                    BatchNormRelu(C + 1, In("C", C)) +
                                    Convolution(C + 1, In("B", C + 1), DIV8(p.GrowthRate), 3, 3, 1, 1, 1, 1) +
                                    (p.Dropout &gt; 0 ? Dropout(C + 1, In("C", C + 1)) + Concat(CC, In("B", C) + "," + In("D", C + 1)) : Concat(CC, In("B", C) + "," + In("C", C + 1))));

                                C += 2;
                            }
                            else
                            {
                                blocks.Add(
                                    BatchNormRelu(C, In("P", g)) +
                                    Convolution(C, In("B", C), DIV8(p.GrowthRate), 3, 3, 1, 1, 1, 1) +
                                    (p.Dropout &gt; 0 ? Dropout(C, In("C", C)) + Concat(CC, In("B", C) + "," + In("D", C)) : Concat(CC, In("B", C) + "," + In("C", C))));

                                C++;
                            }

                            channels += p.GrowthRate;
                        }
                    }

                    foreach (var block in blocks)
                        net += block;

                    net +=
                        Convolution(C, In("CC", CC), p.Classes, 1, 1, 1, 1, 0, 0) +
                        BatchNorm(C + 1, In("C", C)) +
                        GlobalAvgPooling(In("B", C + 1)) +
                        "[ACT]" + nwl + "Type=Activation" + nwl + "Inputs=GAP" + nwl + "Activation=Softmax" + nwl + nwl +
                        "[Cost]" + nwl + "Type=Cost" + nwl + "Inputs=ACT" + nwl + "Cost=CategoricalCrossEntropy" + nwl + "Channels=" + to_string(p.Classes);
                }
                break;

            case Scripts.mobilenetv3:
                {
                    var channelsplit = true;
                    var W = p.Width * 16;

                    net +=
                        Convolution(1, "Input", DIV8(W), 3, 3, 1, 1, 1, 1) +
                        BatchNormHardSwish(1, "C1");

                    blocks.Add(
                        Convolution(2, "B1", DIV8(6 * W), 1, 1, 1, 1, 0, 0) +
                        BatchNormHardSwish(2, "C2") +
                        DepthwiseMixedConvolution(3, 3, "B2", 1, 1, channelsplit) +
                        BatchNormHardSwish(3, "DC3") +
                        Convolution(4, "B3", DIV8(W), 1, 1, 1, 1, 0, 0) +
                        BatchNorm(4, "C4"));

                    var A = 1ul;
                    var C = 6ul;

                    for (var g = 1ul; g &lt;= p.Groups; g++)  // 32*32 16*16 8*8 or 28*28 14*14 7*7
                    {
                        if (g &gt; 1)
                        {
                            W *= 2;

                            var group = In("SE", C + 1);
                            var strSE =
                                p.SqueezeExcitation ? GlobalAvgPooling(In("B", C + 1), group) +
                                Convolution(1, group + "GAP", DIV8((6 * W) / 4), 1, 1, 1, 1, 0, 0, group) +
                                BatchNormHardSwish(1, group + "C1", group) +
                                Convolution(2, group + "B1", DIV8(6 * W), 1, 1, 1, 1, 0, 0, group) +
                                BatchNormHardLogistic(2, group + "C2", group) +
                                ChannelMultiply(In("B", C + 1) + "," + group + "B2", group) +
                                Convolution(C + 2, group + "CM", DIV8(W), 1, 1, 1, 1, 0, 0) :
                                Convolution(C + 2, In("B", C + 1), DIV8(W), 1, 1, 1, 1, 0, 0);

                            //auto strDropout = p.Dropout &gt; 0 ? Dropout(C, In("A", A)) +
                            //    Convolution(C, In("D", C), 6 * W, 1, 1, 1, 1, 0, 0) :
                            //    Convolution(C, In("A", A), 6 * W, 1, 1, 1, 1, 0, 0);

                            blocks.Add(
                                Convolution(C, In("A", A), DIV8(6 * W), 1, 1, 1, 1, 0, 0) +
                                BatchNormHardSwish(C, In("C", C)) +
                                DepthwiseMixedConvolution(3, C + 1, In("B", C), 2, 2, channelsplit) +
                                BatchNormHardSwish(C + 1, In("DC", C + 1)) +
                                strSE +
                                BatchNorm(C + 2, In("C", C + 2)));

                            C += 3;
                        }

                        for (var i = 1ul; i &lt; p.Iterations; i++)
                        {
                            var strOutputLayer = (i == 1 &amp;&amp; g &gt; 1) ? In("B", C - 1) : (i == 1 &amp;&amp; g == 1) ? "B4" : In("A", A);

                            var group = In("SE", C + 1);

                            var strSE =
                                p.SqueezeExcitation ? GlobalAvgPooling(In("B", C + 1), group) +
                                Convolution(1, group + "GAP", DIV8((6 * W) / 4), 1, 1, 1, 1, 0, 0, group) +
                                BatchNormHardSwish(1, group + "C1", group) +
                                Convolution(2, group + "B1", DIV8(6 * W), 1, 1, 1, 1, 0, 0, group) +
                                BatchNormHardLogistic(2, group + "C2", group) +
                                ChannelMultiply(In("B", C + 1) + "," + group + "B2", group) +
                                Convolution(C + 2, group + "CM", DIV8(W), 1, 1, 1, 1, 0, 0) :
                                Convolution(C + 2, In("B", C + 1), DIV8(W), 1, 1, 1, 1, 0, 0);

                            blocks.Add(
                                Convolution(C, strOutputLayer, DIV8(6 * W), 1, 1, 1, 1, 0, 0) +
                                BatchNormHardSwish(C, In("C", C)) +
                                DepthwiseMixedConvolution(g, C + 1, In("B", C), 1, 1, channelsplit) +
                                BatchNormHardSwish(C + 1, In("DC", C + 1)) +
                                strSE +
                                BatchNorm(C + 2, In("C", C + 2)) +
                                Add(A + 1, In("B", C + 2) + "," + strOutputLayer));

                            A++;
                            C += 3;
                        }
                    }

                    foreach (var block in blocks)
                        net += block;

                    net +=
                        BatchNormHardSwish(C, In("A", A)) +
                        Convolution(C, In("B", C), p.Classes, 1, 1, 1, 1, 0, 0) +
                        BatchNorm(C + 1, In("C", C)) +
                        GlobalAvgPooling(In("B", C + 1)) +
                        "[ACT]" + nwl + "Type=Activation" + nwl + "Inputs=GAP" + nwl + "Activation=Softmax" + nwl + nwl +
                        "[Cost]" + nwl + "Type=Cost" + nwl + "Inputs=ACT" + nwl + "Cost=CategoricalCrossEntropy" + nwl + "Channels=" + to_string(p.Classes);
                }
                break;

            case Scripts.resnet:
                {
                    var bn = p.Bottleneck ? 1ul : 0ul;
                    const Float K = 2;
                    var W = p.Width * 16;
                    var A = 1ul;
                    var C = 5ul;

                    net += Convolution(1, "Input", DIV8(W), 3, 3, 1, 1, 1, 1);

                    if (p.Bottleneck)
                    {
                        blocks.Add(
                            BatchNormRelu(1, "C1") +
                            Convolution(2, "B1", DIV8(W), 1, 1, 1, 1, 0, 0) +
                            BatchNormRelu(2, "C2") +
                            Convolution(3, "B2", DIV8((size_t)(K * W / 4)), 3, 3, 1, 1, 1, 1) +
                            (p.Dropout &gt; 0 ? BatchNormReluDropout(3, "C3") : BatchNormRelu(3, "C3")) +
                            Convolution(4, "B3", DIV8(W), 1, 1, 1, 1, 0, 0) +
                            Convolution(5, "B1", DIV8(W), 1, 1, 1, 1, 0, 0) +
                            Add(1, "C4,C5"));

                        C = 6;
                    }
                    else
                    {
                        blocks.Add(
                            BatchNormRelu(1, "C1") +
                            Convolution(2, "B1", DIV8(W), 3, 3, 1, 1, 1, 1) +
                            (p.Dropout &gt; 0 ? BatchNormReluDropout(2, "C2") : BatchNormRelu(2, "C2")) +
                            Convolution(3, "B2", DIV8(W), 3, 3, 1, 1, 1, 1) +
                            Convolution(4, "B1", DIV8(W), 1, 1, 1, 1, 0, 0) +
                            Add(1, "C3,C4"));
                    }

                    for (var g = 0ul; g &lt; p.Groups; g++)  // 32*32 16*16 8*8 or 28*28 14*14 7*7
                    {
                        if (g &gt; 0)
                        {
                            W *= 2;

                            var strChannelZeroPad = p.ChannelZeroPad ?
                                ("[AVG" + to_string(g) + "]" + nwl + "Type=AvgPooling" + nwl + "Inputs=A" + to_string(A) + nwl + "Kernel=3,3" + nwl + "Stride=2,2" + nwl + "Pad=1,1" + nwl + nwl +
                                "[CZP" + to_string(g) + "]" + nwl + "Type=ChannelZeroPad" + nwl + "Inputs=AVG" + to_string(g) + nwl + "Channels=" + to_string(W) + nwl + nwl +
                                Add(A + 1, In("C", C + 1 + bn) + "," + In("CZP", g))) :
                                (Convolution(C + 2 + bn, In("B", C), DIV8(W), 1, 1, 2, 2, 0, 0) +
                                Add(A + 1, In("C", C + 1 + bn) + "," + In("C", C + 2 + bn)));

                            if (p.Bottleneck)
                            {

                                blocks.Add(
                                    BatchNormRelu(C, In("A", A)) +
                                    Convolution(C, In("B", C), DIV8(W), 1, 1, 2, 2, 0, 0) +
                                    BatchNormRelu(C + 1, In("C", C)) +
                                    Convolution(C + 1, In("B", C + 1), DIV8((size_t)(K * W / 4)), 3, 3, 1, 1, 1, 1) +
                                    (p.Dropout &gt; 0 ? BatchNormReluDropout(C + 2, In("C", C + 1)) : BatchNormRelu(C + 2, In("C", C + 1))) +
                                    Convolution(C + 2, In("B", C + 2), DIV8(W), 1, 1, 1, 1, 0, 0) +
                                    strChannelZeroPad);
                            }
                            else
                            {
                                blocks.Add(
                                    BatchNormRelu(C, In("A", A)) +
                                    Convolution(C, In("B", C), DIV8(W), 3, 3, 2, 2, 1, 1) +
                                    (p.Dropout &gt; 0 ? BatchNormReluDropout(C + 1, In("C", C)) : BatchNormRelu(C + 1, In("C", C))) +
                                    Convolution(C + 1, In("B", C + 1), DIV8(W), 3, 3, 1, 1, 1, 1) +
                                    strChannelZeroPad);
                            }

                            A++;
                            if (p.ChannelZeroPad)
                                C += 2 + bn;
                            else
                                C += 3 + bn;
                        }

                        for (var i = 1u; i &lt; p.Iterations; i++)
                        {
                            if (p.Bottleneck)
                            {
                                blocks.Add(
                                    BatchNormRelu(C, In("A", A)) +
                                    Convolution(C, In("B", C), DIV8(W), 1, 1, 1, 1, 0, 0) +
                                    BatchNormRelu(C + 1, In("C", C)) +
                                    Convolution(C + 1, In("B", C + 1), DIV8((size_t)(K * W / 4)), 3, 3, 1, 1, 1, 1) +
                                    (p.Dropout &gt; 0 ? BatchNormReluDropout(C + 2, In("C", C + 1)) : BatchNormRelu(C + 2, In("C", C + 1))) +
                                    Convolution(C + 2, In("B", C + 2), DIV8(W), 1, 1, 1, 1, 0, 0) +
                                    Add(A + 1, In("C", C + 2) + "," + In("A", A)));
                            }
                            else
                            {
                                blocks.Add(
                                    BatchNormRelu(C, In("A", A)) +
                                    Convolution(C, In("B", C), DIV8(W), 3, 3, 1, 1, 1, 1) +
                                    (p.Dropout &gt; 0 ? BatchNormReluDropout(C + 1, In("C", C)) : BatchNormRelu(C + 1, In("C", C))) +
                                    Convolution(C + 1, In("B", C + 1), DIV8(W), 3, 3, 1, 1, 1, 1) +
                                    Add(A + 1, In("C", C + 1) + "," + In("A", A)));
                            }

                            A++; C += 2 + bn;
                        }
                    }

                    foreach (var block in blocks)
                        net += block;

                    net +=
                        BatchNormRelu(C, In("A", A)) +
                        Convolution(C, In("B", C), p.Classes, 1, 1, 1, 1, 0, 0) +
                        BatchNorm(C + 1, In("C", C)) +
                        GlobalAvgPooling(In("B", C + 1)) +
                        "[ACT]" + nwl + "Type=Activation" + nwl + "Inputs=GAP" + nwl + "Activation=Softmax" + nwl + nwl +
                        "[Cost]" + nwl + "Type=Cost" + nwl + "Inputs=ACT" + nwl + "Cost=CategoricalCrossEntropy" + nwl + "Channels=" + to_string(p.Classes);
                }
                break;

            case Scripts.shufflenetv2:
                {
                    const bool channelsplit = true;
                    var W = p.Width * 16;

                    net += Convolution(1, "Input", DIV8(W), 3, 3, 1, 1, 1, 1);

                    blocks.Add(
                        BatchNormRelu(1, "C1") +
                        Convolution(2, "B1", DIV8(W), 1, 1, 1, 1, 0, 0) +
                        BatchNormRelu(2, "C2") +
                        DepthwiseConvolution(3, "B2") +
                        BatchNorm(3, "DC3") +
                        Convolution(4, "B3", DIV8(W), 1, 1, 1, 1, 0, 0) +
                        BatchNormRelu(4, "C4") +
                        Convolution(5, "B1", DIV8(W), 1, 1, 1, 1, 0, 0) +
                        Concat(1, "C5,B4"));

                    var C = 6ul;
                    var A = 1ul;

                    for (var g = 1ul; g &lt;= p.Groups; g++)  // 32*32 16*16 8*8 or 28*28 14*14 7*7
                    {
                        if (g &gt; 1)
                        {
                            W *= 2;

                            blocks.Add(
                                Convolution(C, In("CC", A), DIV8(W), 1, 1, 1, 1, 0, 0) +
                                BatchNormRelu(C + 1, In("C", C)) +
                                DepthwiseMixedConvolution(0, C + 1, In("B", C + 1), 2, 2, channelsplit) +
                                BatchNorm(C + 2, In("DC", C + 1)) +
                                Convolution(C + 2, In("B", C + 2), DIV8(W), 1, 1, 1, 1, 0, 0) +
                                BatchNormRelu(C + 3, In("C", C + 2)) +
                                DepthwiseMixedConvolution(0, C + 3, In("CC", A), 2, 2, channelsplit) +
                                BatchNorm(C + 4, In("DC", C + 3)) +
                                Convolution(C + 4, In("B", C + 4), DIV8(W), 1, 1, 1, 1, 0, 0) +
                                BatchNormRelu(C + 5, In("C", C + 4)) +
                                Concat(A + 1, In("B", C + 5) + "," + In("B", C + 3)));

                            A++; C += 5;
                        }

                        for (var i = 1ul; i &lt; p.Iterations; i++)
                        {
                            blocks.Add(
                                ChannelShuffle(A, In("CC", A), 2) +
                                ChannelSplit(A, In("CSH", A), 2, 1, "L") + ChannelSplit(A, In("CSH", A), 2, 2, "R") +
                                Convolution(C, In("RCS", A), DIV8(W), 1, 1, 1, 1, 0, 0) +
                                BatchNormRelu(C + 1, In("C", C)) +
                                DepthwiseMixedConvolution(0, C + 1, In("B", C + 1), 1, 1, channelsplit) +
                                BatchNorm(C + 2, In("DC", C + 1)) +
                                Convolution(C + 2, In("B", C + 2), DIV8(W), 1, 1, 1, 1, 0, 0) +
                                BatchNormRelu(C + 3, In("C", C + 2)) +
                                Concat(A + 1, In("LCS", A) + "," + In("B", C + 3)));

                            A++; C += 3;
                        }
                    }

                    foreach (var block in blocks)
                        net += block;

                    net +=
                        Convolution(C, In("CC", A), p.Classes, 1, 1, 1, 1, 0, 0) +
                        BatchNorm(C + 1, In("C", C)) +
                        GlobalAvgPooling(In("B", C + 1)) +
                        "[ACT]" + nwl + "Type=Activation" + nwl + "Inputs=GAP" + nwl + "Activation=Softmax" + nwl + nwl +
                        "[Cost]" + nwl + "Type=Cost" + nwl + "Inputs=ACT" + nwl + "Cost=CategoricalCrossEntropy" + nwl + "Channels=" + to_string(p.Classes);
                }
                break;
        }

        return net;
    }
}
}</Value>
    </Setting>
    <Setting Name="EditSplitPositionB" Type="System.Windows.GridLength" Scope="User">
      <Value Profile="(Default)">840</Value>
    </Setting>
    <Setting Name="PlainFormat" Type="System.Boolean" Scope="User">
      <Value Profile="(Default)">False</Value>
    </Setting>
  </Settings>
</SettingsFile>